using MeasureBase
using Test
using Base.Iterators: take
using Random
using LinearAlgebra
using KeywordCalls
using Statistics


function draw2(Î¼)
    x = rand(Î¼)
    y = rand(Î¼)
    while x == y
        y = rand(Î¼)
    end
    return (x,y)
end

const sqrt2Ï€ = sqrt(2Ï€)

@testset "Parameterized Measures" begin
    @measure Normal(Î¼,Ïƒ)
    @kwstruct Normal(Î¼)
    @kwstruct Normal()
    
    MeasureBase.basemeasure(::Normal)= (1/sqrt2Ï€) * Lebesgue(â„)
    MeasureBase.logdensity(d::Normal{(:Î¼,:Ïƒ)}, x) = -log(d.Ïƒ) - (x - d.Î¼)^2 / (2 * d.Ïƒ^2)
    MeasureBase.logdensity(d::Normal{(:Î¼,)}, x) = - (x - d.Î¼)^2 / 2
    MeasureBase.logdensity(d::Normal{()}, x) = - x^2 / 2

    Base.rand(rng::Random.AbstractRNG, T::Type, d::Normal{(:Î¼,:Ïƒ)}) = d.Î¼ + d.Ïƒ * randn(rng, T)
    Base.rand(rng::Random.AbstractRNG, T::Type, d::Normal{(:Î¼,)}) = d.Î¼ + randn(rng, T)
    Base.rand(rng::Random.AbstractRNG, T::Type, d::Normal{()}) = randn(rng, T)

    MeasureBase.representative(d::Normal{(:Î¼,:Ïƒ)}) = d.Ïƒ > 0.0 ? Lebesgue(â„) : Dirac(d.Î¼)
    MeasureBase.representative(d::Normal{(:Î¼,)}) = Lebesgue(â„)

    # Leave this undefined to test fallback inference algorithm
    # MeasureBase.representative(::Normal) = Lebesgue(â„)

    @test Normal(2,4) == Normal(Î¼=2, Ïƒ=4)
    @test Normal(Ïƒ=4, Î¼=2) == Normal(Î¼=2, Ïƒ=4)
    @test logdensity(Normal(), 3) == logdensity(Normal(0,1), 3)

    x = randn()
    @test_broken logdensity(Normal(3,2), Lebesgue(â„), x) â‰ˆ logdensity(Normal(3,2), Normal(), x ) + logdensity(Normal(), Lebesgue(â„),x)
    @test_broken ğ’¹(Normal(3,2), Normal())(x) â‰ˆ logdensity(Normal(3,2), Normal(), x)
end

@testset "Density" begin
    x = randn()
    f(x) = -x^2
    Î¼ = Normal()
    Î½ = Lebesgue(â„)
    @test_broken ğ’¹(âˆ«(f, Î¼), Î¼)(x) â‰ˆ f(x)
    @test_broken logdensity(âˆ«(ğ’¹(Î¼, Î½), Î½), x) â‰ˆ logdensity(Î¼, x)
end


@testset "Kernel" begin
    Îº = kernel(identity, Dirac)
    @test rand(Îº(1.1)) == 1.1
    @test kernelize(Normal(0,1)) == (Kernel{Normal, UnionAll}(NamedTuple{(:Î¼, :Ïƒ), T} where T<:Tuple), (0, 1))
end

@testset "SpikeMixture" begin
    @test rand(SpikeMixture(Dirac(0), 0.5)) == 0
    @test rand(SpikeMixture(Dirac(1), 1.0)) == 1
    w = 1/3
    m = SpikeMixture(Normal(), w)
    bm = basemeasure(m)
    @test (bm.s*bm.w)*bm.m == 1.0*basemeasure(Normal())
    @test density(m, 1.0)*(bm.s*bm.w) == w*density(Normal(),1.0)
    @test density(m, 0)*(bm.s*(1-bm.w)) â‰ˆ (1-w)
end

@testset "For" begin
    FORDISTS = [
        For(1:10) do j Normal(Î¼=j) end
        For(4,3) do Î¼,Ïƒ Normal(Î¼,Ïƒ) end
        For(1:4, 1:4) do Î¼,Ïƒ Normal(Î¼,Ïƒ) end
        For(eachrow(rand(4,2))) do x Normal(x[1], x[2]) end
        For(rand(4), rand(4)) do Î¼,Ïƒ Normal(Î¼,Ïƒ) end
    ]

    for d in FORDISTS
        @test logdensity(d, rand(d)) isa Float64
    end
end

function â‹…(Î¼::Normal, kernel) 
    m = kernel(Î¼)
    Normal(Î¼ = m.Î¼.Î¼, Ïƒ = sqrt(m.Î¼.Ïƒ^2 + m.Ïƒ^2))
end

"""
    ConstantMap(Î²)
Represents a function `f = ConstantMap(Î²)`
such that `f(x) == Î²`.
"""
struct ConstantMap{T}
    x::T
end
(a::ConstantMap)(x) = a.x
(a::ConstantMap)() = a.x

struct AffineMap{S,T}
    B::S
    Î²::T
end
(a::AffineMap)(x) = a.B*x + a.Î²
(a::AffineMap)(p::Normal) = Normal(Î¼ = a.B*mean(p) + a.Î², Ïƒ = sqrt(a.B*p.Ïƒ^2*a.B'))

@testset "DynamicFor" begin
    mc = Chain(Normal(Î¼=0.0)) do x Normal(Î¼=x) end
    r = rand(mc)
   
    # Check that `r` is now deterministic
    @test logdensity(mc, take(r, 100)) == logdensity(mc, take(r, 100))
    
    d2 = For(r) do x Normal(Î¼=x) end  

    @test_broken let r2 = rand(d2)
        logdensity(d2, take(r2, 100)) == logdensity(d2, take(r2, 100))
    end
end

@testset "LogLikelihood" begin
    d = Normal()
    â„“ = LogLikelihood(Normal{(:Î¼,)}, 3.0) 
    @test logdensity(d âŠ™ â„“, 2.0) == logdensity(d, 2.0) + logdensity(â„“, 2.0)
end
